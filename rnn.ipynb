{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad41b71d",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Uczenie-sekwencji-i-sieci-RNN\" data-toc-modified-id=\"Uczenie-sekwencji-i-sieci-RNN-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Uczenie sekwencji i sieci RNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Przewidywanie-szeregów-czasowych\" data-toc-modified-id=\"Przewidywanie-szeregów-czasowych-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Przewidywanie szeregów czasowych</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sztuczne-dane\" data-toc-modified-id=\"Sztuczne-dane-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Sztuczne dane</a></span></li></ul></li><li><span><a href=\"#Okno-przesuwne\" data-toc-modified-id=\"Okno-przesuwne-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Okno przesuwne</a></span></li><li><span><a href=\"#Funkcja-timeseries_dataset_from_array()\" data-toc-modified-id=\"Funkcja-timeseries_dataset_from_array()-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Funkcja timeseries_dataset_from_array()</a></span></li><li><span><a href=\"#Podział-na-część-testową-i-treningową\" data-toc-modified-id=\"Podział-na-część-testową-i-treningową-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Podział na część testową i treningową</a></span></li><li><span><a href=\"#Poziom-bazowy-predykcji\" data-toc-modified-id=\"Poziom-bazowy-predykcji-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Poziom bazowy predykcji</a></span></li><li><span><a href=\"#Model-RNN-prdykcji-szeregu-czasowego\" data-toc-modified-id=\"Model-RNN-prdykcji-szeregu-czasowego-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Model RNN prdykcji szeregu czasowego</a></span></li><li><span><a href=\"#Trening\" data-toc-modified-id=\"Trening-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Trening</a></span></li><li><span><a href=\"#Wykres-zmian-funkcji-kosztu-i-poprawności\" data-toc-modified-id=\"Wykres-zmian-funkcji-kosztu-i-poprawności-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Wykres zmian funkcji kosztu i poprawności</a></span></li><li><span><a href=\"#Przewidywanie-kolejnej-wartości-sekwencji\" data-toc-modified-id=\"Przewidywanie-kolejnej-wartości-sekwencji-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Przewidywanie kolejnej wartości sekwencji</a></span></li><li><span><a href=\"#Przewidywanie-sekwencji\" data-toc-modified-id=\"Przewidywanie-sekwencji-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Przewidywanie sekwencji</a></span></li><li><span><a href=\"#Generowanie-sekwencji-predykcji---model-autoregresji\" data-toc-modified-id=\"Generowanie-sekwencji-predykcji---model-autoregresji-1.11\"><span class=\"toc-item-num\">1.11&nbsp;&nbsp;</span>Generowanie sekwencji predykcji - model autoregresji</a></span></li><li><span><a href=\"#Porównanie-sekwencji-rzeczywistej-z-wynikiem-autoregresji\" data-toc-modified-id=\"Porównanie-sekwencji-rzeczywistej-z-wynikiem-autoregresji-1.12\"><span class=\"toc-item-num\">1.12&nbsp;&nbsp;</span>Porównanie sekwencji rzeczywistej z wynikiem autoregresji</a></span></li><li><span><a href=\"#Wielowarstwowe-sieci-RNN\" data-toc-modified-id=\"Wielowarstwowe-sieci-RNN-1.13\"><span class=\"toc-item-num\">1.13&nbsp;&nbsp;</span>Wielowarstwowe sieci RNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ćwiczenie\" data-toc-modified-id=\"Ćwiczenie-1.13.1\"><span class=\"toc-item-num\">1.13.1&nbsp;&nbsp;</span>Ćwiczenie</a></span></li></ul></li><li><span><a href=\"#Warstwy-rekurencyjne-dwukierunkowe\" data-toc-modified-id=\"Warstwy-rekurencyjne-dwukierunkowe-1.14\"><span class=\"toc-item-num\">1.14&nbsp;&nbsp;</span>Warstwy rekurencyjne dwukierunkowe</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ćwiczenie\" data-toc-modified-id=\"Ćwiczenie-1.14.1\"><span class=\"toc-item-num\">1.14.1&nbsp;&nbsp;</span>Ćwiczenie</a></span></li></ul></li><li><span><a href=\"#Model-językowy---generowanie-tekstu\" data-toc-modified-id=\"Model-językowy---generowanie-tekstu-1.15\"><span class=\"toc-item-num\">1.15&nbsp;&nbsp;</span>Model językowy - generowanie tekstu</a></span></li><li><span><a href=\"#Dane:-Song-Lirycs\" data-toc-modified-id=\"Dane:-Song-Lirycs-1.16\"><span class=\"toc-item-num\">1.16&nbsp;&nbsp;</span>Dane: Song Lirycs</a></span></li><li><span><a href=\"#Przykładowa-piosenka\" data-toc-modified-id=\"Przykładowa-piosenka-1.17\"><span class=\"toc-item-num\">1.17&nbsp;&nbsp;</span>Przykładowa piosenka</a></span></li><li><span><a href=\"#Przygotowanie-korpusu\" data-toc-modified-id=\"Przygotowanie-korpusu-1.18\"><span class=\"toc-item-num\">1.18&nbsp;&nbsp;</span>Przygotowanie korpusu</a></span></li><li><span><a href=\"#Zamiana-wyrazów-na-tokeny\" data-toc-modified-id=\"Zamiana-wyrazów-na-tokeny-1.19\"><span class=\"toc-item-num\">1.19&nbsp;&nbsp;</span>Zamiana wyrazów na tokeny</a></span></li><li><span><a href=\"#Zamiana-tekstu-na-sekwencje-tokenów\" data-toc-modified-id=\"Zamiana-tekstu-na-sekwencje-tokenów-1.20\"><span class=\"toc-item-num\">1.20&nbsp;&nbsp;</span>Zamiana tekstu na sekwencje tokenów</a></span></li><li><span><a href=\"#Sekwencje-wejściowe-i-etykiety\" data-toc-modified-id=\"Sekwencje-wejściowe-i-etykiety-1.21\"><span class=\"toc-item-num\">1.21&nbsp;&nbsp;</span>Sekwencje wejściowe i etykiety</a></span></li><li><span><a href=\"#Sekwencje-o-stałej-szerokości\" data-toc-modified-id=\"Sekwencje-o-stałej-szerokości-1.22\"><span class=\"toc-item-num\">1.22&nbsp;&nbsp;</span>Sekwencje o stałej szerokości</a></span></li><li><span><a href=\"#Przygotowanie-etykiet\" data-toc-modified-id=\"Przygotowanie-etykiet-1.23\"><span class=\"toc-item-num\">1.23&nbsp;&nbsp;</span>Przygotowanie etykiet</a></span></li><li><span><a href=\"#Osadzanie-słów:-warstwa-Embedding\" data-toc-modified-id=\"Osadzanie-słów:-warstwa-Embedding-1.24\"><span class=\"toc-item-num\">1.24&nbsp;&nbsp;</span>Osadzanie słów: warstwa Embedding</a></span></li><li><span><a href=\"#Osadzanie-słów\" data-toc-modified-id=\"Osadzanie-słów-1.25\"><span class=\"toc-item-num\">1.25&nbsp;&nbsp;</span>Osadzanie słów</a></span></li><li><span><a href=\"#Model-generujący-teksty-piosenek\" data-toc-modified-id=\"Model-generujący-teksty-piosenek-1.26\"><span class=\"toc-item-num\">1.26&nbsp;&nbsp;</span>Model generujący teksty piosenek</a></span></li><li><span><a href=\"#Trening\" data-toc-modified-id=\"Trening-1.27\"><span class=\"toc-item-num\">1.27&nbsp;&nbsp;</span>Trening</a></span></li><li><span><a href=\"#Generowanie-tekstu\" data-toc-modified-id=\"Generowanie-tekstu-1.28\"><span class=\"toc-item-num\">1.28&nbsp;&nbsp;</span>Generowanie tekstu</a></span></li><li><span><a href=\"#Wprowadzanie-różnowodności-(losoości)-do-wyjścia\" data-toc-modified-id=\"Wprowadzanie-różnowodności-(losoości)-do-wyjścia-1.29\"><span class=\"toc-item-num\">1.29&nbsp;&nbsp;</span>Wprowadzanie różnowodności (losoości) do wyjścia</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ćwiczenie\" data-toc-modified-id=\"Ćwiczenie-1.29.1\"><span class=\"toc-item-num\">1.29.1&nbsp;&nbsp;</span>Ćwiczenie</a></span></li></ul></li><li><span><a href=\"#Zadanie:-przewidywanie-ceny-akcji\" data-toc-modified-id=\"Zadanie:-przewidywanie-ceny-akcji-1.30\"><span class=\"toc-item-num\">1.30&nbsp;&nbsp;</span>Zadanie: przewidywanie ceny akcji</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c23ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Uczenie sekwencji i sieci RNN\n",
    "\n",
    "* przewidywanie szeregów czasowych\n",
    "* model języka i generowanie tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2ba458-02d1-4e53-ab02-4d02499e41be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# TF log level: 0 debug (default), 1 info, 2 warning, 3 error\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2003d4c2-6eab-42d4-a7e8-9d34dcf9fbd5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przewidywanie szeregów czasowych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b010a-5d09-4989-a519-59d9677d9ba7",
   "metadata": {},
   "source": [
    "### Sztuczne dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ef79a-1baf-4f37-bf48-c0183f6e09b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "\n",
    "time = np.arange(N)\n",
    "signal = 0.8*np.sin(time/700) + 0.15*np.sin(time/40)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(signal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f44b88",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Okno przesuwne\n",
    "\n",
    "* szerokość okna ``window=50`` punktów czasowych\n",
    "* celem przewidzenie kolejnej wartości w sekwencji \n",
    "\n",
    "![](https://www.tensorflow.org/static/tutorials/structured_data/images/split_window.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f22bf-1d71-4138-a92f-de051182c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 50\n",
    "\n",
    "X = np.array(\n",
    "    [signal[t: t+window] for t in time[:-window]] \n",
    ")\n",
    "\n",
    "Y = signal[time[window:]]\n",
    "\n",
    "print('Dane treningowe X', X.shape)\n",
    "print('Target ', Y.shape)\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.plot(range(window), X[50], 'o-', label='time series')\n",
    "plt.plot([window], Y[50], 'or', label='target')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f267c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Podział na część testową i treningową"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423b5b4-8ab7-4e4e-a528-d2ebea040e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 9000\n",
    "\n",
    "x_train = X[:n_train]\n",
    "y_train = Y[:n_train]\n",
    "x_val = X[n_train:]\n",
    "y_val = Y[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fc5674",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Poziom bazowy predykcji\n",
    "\n",
    "Wartość MSE i MAE dla modelu, który powtarza w kolejnym kroku ostatnią wartość"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b5617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = x_val[:, -1]\n",
    "\n",
    "dv = y_pred - y_val \n",
    "mse = np.mean( np.sum(dv**2) )\n",
    "mae = np.mean(np.abs(dv))\n",
    "\n",
    "print(f'MSE {mse}, MAE {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d57a3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model RNN prdykcji szeregu czasowego\n",
    "\n",
    "* wejście rozmiaru ``[czas, zmienne]``\n",
    "* [warstwy rekurencyjne w Keras](https://keras.io/api/layers/recurrent_layers/)\n",
    "* warstwa rekurencyjna LSTM  [tf.keras.layers.LSTM](https://keras.io/api/layers/recurrent_layers/lstm/)\n",
    "* wyjście liniowe, funkcja kosztu MSE, metryka MAE (Mean Absolute Error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91694f61-1989-4622-a5a6-350dff0f64fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = Input((window, 1 ))\n",
    "x = LSTM(20)(inputs)\n",
    "output = Dense(1)(x)\n",
    "\n",
    "model = Model(inputs, output)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9f9f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4c348",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 30\n",
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226027a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wykres zmian funkcji kosztu i poprawności"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19cfb26-ba65-41e0-869d-427ea9eda2c4",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].plot(history.history['loss'], '-r', label=\"Training\")\n",
    "ax[0].plot(history.history['val_loss'], '-b', label=\"Validation\")\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(history.history['mae'], '-r', label=\"Training\")\n",
    "ax[1].plot(history.history['val_mae'], '-b', label=\"Validation\")\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Mean Absolute Error')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43c194",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przewidywanie kolejnej wartości sekwencji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5791f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "\n",
    "pred = model.predict(x_val[i].reshape(1, window, 1)  )\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.plot(range(window), x_val[i], 'o-', label='time series')\n",
    "plt.plot([window], y_val[i], 'or', label='true target')\n",
    "plt.plot([window], pred[0][0], 'xb', label='predicted')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf3f18a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przewidywanie sekwencji\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0993fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val.reshape(x_val.shape[0], window, 1))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_val, label=\"Ground truth\")\n",
    "plt.plot(y_pred, label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse, mae = model.evaluate(x_val, y_val)\n",
    "print(f'MSE {mse}, MAE {mae}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d677b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generowanie sekwencji predykcji - model autoregresji\n",
    "\n",
    "Kolejka FIFO [collections.deque](https://docs.python.org/3/library/collections.html#collections.deque)\n",
    "* ``append()`` dodaj do kolejki\n",
    "* ``popleft()`` wyjmij z kolejki\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ff735-61fa-4f11-97c3-a2dee8001d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  collections import deque\n",
    "i = 0\n",
    "\n",
    "d = deque([1, 2, 3])\n",
    "print(d)\n",
    "\n",
    "d.popleft()\n",
    "print(d)\n",
    "\n",
    "d.append(4)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92016739",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "d = deque(X_test[0, :window])\n",
    "\n",
    "for t in range(950):\n",
    "    y = model.predict(np.array(d).reshape(1, window, 1), verbose=0)[0,0]\n",
    "    print(\"%.2f\" % y, end=\" \")\n",
    "    predictions.append(y)\n",
    "    d.popleft()\n",
    "    d.append(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71775c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Porównanie sekwencji rzeczywistej z wynikiem autoregresji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811189b-a71c-42db-8f17-3edf65b81278",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(T_test, '-', label=\"Ground truth\")\n",
    "plt.plot(predictions, '-', label=\"LSTM Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e53c9f1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wielowarstwowe sieci RNN\n",
    "\n",
    "Parametr ``return_sequences`` w warstwach rekurencyjnych\n",
    "* ``return_sequences=False`` (domyślnie) zwraca pojedyncze wyjście podsumowujące sekwencję\n",
    "* ``return_sequences=True`` zwraca wyjście dla każdego punktu sekwencji  (ewentualne wejście dla kolejnej warstwy rekurencyjnej)\n",
    "\n",
    "### Ćwiczenie\n",
    "\n",
    "Zbuduj model przewidywania szeregu czasowego składający się co najmniej z dwóch warstw rekurencyjnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4179655",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c979970",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Warstwy rekurencyjne dwukierunkowe\n",
    "\n",
    "Warstwa [tf.keras.layers.Bidirectional](https://keras.io/api/layers/recurrent_layers/bidirectional/) opakowuje  warstwę rekurencyjną (np. LSTM) tworząc jej odwojowaną wersję przetwarzającą sekwencję w przeciwnym kierunku wgl. czasu\n",
    "```python\n",
    "tf.keras.layers.Bidirectional(\n",
    "    layer, merge_mode=\"concat\", weights=None, backward_layer=None, **kwargs\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input( (10, 5) ))\n",
    "model.add(LSTM(1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input( (10, 5) ))\n",
    "model.add(Bidirectional(LSTM(1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33543508",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ćwiczenie\n",
    "\n",
    "Zbuduj model sieci przewidującej szereg czasowy z wykorzystaniem warstw przetwarzających sygnał w dwóch kierunkach czasowych i porownaj wyniki z poprzednim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2abe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf54c99",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model językowy - generowanie tekstu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db738c",
   "metadata": {},
   "source": [
    "## Dane: Song Lirycs\n",
    "\n",
    "Zbiór danych piosenek [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics) \n",
    "\n",
    "* cały zbiór zawiera 57650 piosenek\n",
    "* wybierzmy pierwsze 250 piosenek \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8fe4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "n_songs = 250\n",
    "\n",
    "dataset = pd.read_csv('dane/songdata.csv.gz', compression='gzip',  dtype=str)[:n_songs]\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef6726",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przykładowa piosenka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685eb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Artysta:', dataset['artist'][0])\n",
    "print('Tytuł: %s\\n' % dataset['song'][0])\n",
    "print(dataset['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541514d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przygotowanie korpusu \n",
    "\n",
    "* każdy wers piosenki potraktujemy jako osobną sekwencję\n",
    "* usuńmy puste linie tekstu i inne artefakty (znaki interpunkcyjne, zamieniamy wielkie litery na małe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1aefdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# zbiór piosenek, usuwamy znaki przestankowe\n",
    "songs = dataset['text'].str.replace('[{}]'.format(string.punctuation), '', regex=False)\n",
    "\n",
    "# Zamiana na małe litery\n",
    "songs = songs.str.lower()\n",
    "  \n",
    "# Zamiana tekstu piosenek na długi, pojedynczy napis\n",
    "lyrics = songs.str.cat()\n",
    "\n",
    "# dzielimy tekst na linie\n",
    "corpus = lyrics.split('\\n')\n",
    "  \n",
    "# Usuwamy nadmiarowe białe znaki\n",
    "for l in range(len(corpus)):\n",
    "    corpus[l] = corpus[l].rstrip()\n",
    "\n",
    "# Usuwamy puste linie\n",
    "corpus = [l for l in corpus if l != '']\n",
    "\n",
    "print(f'Ilość linii {len(corpus)}')\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b753e70e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zamiana wyrazów na tokeny\n",
    "\n",
    "Klasa [tf.keras.preprocessing.text.Tokenizer()](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer)\n",
    "* tworzy słownik wyrazów, każdemu wyrazowi przypisywana jest unikatowa liczba całkowita dodatnia\n",
    "* ``num_words`` ogranicza wielkość słownika do najczęściej występujących słów\n",
    "* ``oov_token`` (out of vocabulary) lista wyrazów, z poza słownika, które otrzymają token w słowniku (np. do obsługi szczególnych elementów, np. początek lub koniec sekwencji)\n",
    "* metoda ``fit_on_text()`` buduje indeks słów w oparciu o listę tekstów\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af0692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "\n",
    "num_words=2000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c6733",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "total_words = tokenizer.num_words\n",
    "\n",
    "print('Ilość słów:', total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535183c1",
   "metadata": {},
   "source": [
    "Indeks słów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b25010",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d06bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index['love']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73148c2",
   "metadata": {},
   "source": [
    "Odwzorowanie tokenów na wyrazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bcf956",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.index_word[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe10323",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zamiana tekstu na sekwencje tokenów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de55b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "teksts = [ 'the book of love' , 'Ala ma kota' ]\n",
    "tokenizer.texts_to_sequences( teksts )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c56d29",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sekwencje wejściowe i etykiety\n",
    "\n",
    "* model językowy ma przewidywać najbardziej prawdopodobne kolejne słowo\n",
    "* dokumenty dzielimy na sekwencje wyrazów  (okno przesuwne)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_corpus = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "sequences = []\n",
    "for token_list in token_corpus:\n",
    "    for i in range(2, len(token_list)+1):\n",
    "        sequences.append(token_list[:i])\n",
    "        \n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4f3729",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sekwencje o stałej szerokości\n",
    "\n",
    "* tworzymy sekwencje o stałej długości (weźmy najdłuższa linię)\n",
    "* funkcja [tf.keras.utils.pad_sequences()](https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences) uzupełnia sekwencję zerami do wymaganej długości\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4186f05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "max_sequence_len = max([len(seq) for seq in sequences])\n",
    "\n",
    "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f105658d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przygotowanie etykiet\n",
    "\n",
    "* Dzielimy sekwencję na część \"wejściową\" oraz \"wyjściową\" (przewidywane słowo).\n",
    "* Etykiety kodowane za pomocą *one hot encoding* (klasyfikacja wieloklasowa)\n",
    "* Ilość klas to rozmiar słownika ``total_worlds``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb7c39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
    "\n",
    "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n",
    "\n",
    "print('Sekwencje wejściowe: ', input_sequences.shape)\n",
    "print('Etykiety ', one_hot_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f768246c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Osadzanie słów: warstwa Embedding\n",
    "\n",
    "W naiwnym podejściu sygnał wejściowy składałby się z ``total_worlds`` zmiennych, wejście RNN rozmiaru ``[time, total_worlds]``, to powodowałoby bardzo dużą liczbę parametrów w pierwszej warstwie\n",
    "\n",
    "![](https://www.tensorflow.org/text/guide/images/one-hot.png)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63c5fbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Osadzanie słów\n",
    "\n",
    "* warstwa [Embedding(input_dim, output_dim)](https://keras.io/api/layers/core_layers/embedding/) transformuje sekwencję liczb całkowitych dodatnich (tokenów) na gęstą reprezentację wektorową o wybranej liczbie wymiarów\n",
    "* realizowane przez gęstą (w pełni połączoną) warstwę, uczoną wraz z siecią lub można wykorzystać wcześniej wytrenowane macierze uzyskane na dużych korpusach\n",
    "* odległości obiektów w rzutowanej przestrzeni odzwierciedlają relacje obiektów z oryginalnych sekwencji\n",
    "\n",
    "\n",
    "![](https://www.tensorflow.org/text/guide/images/embedding2.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=total_words, output_dim=64, input_length=max_sequence_len-1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc439a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://i.stack.imgur.com/2PznT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca5185",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model generujący teksty piosenek\n",
    "\n",
    "* warstwa wejściowa [tf.keras.layers.Embedding()](https://keras.io/api/layers/core_layers/embedding/) \n",
    "* warstwa rekurencyjna LSTM (dwukierunkowa)\n",
    "* warstwa wyjściowa o rozmiarze równym ilości słów w słowniku, funkcja aktywacji ``softmax`` \n",
    "* problem klasyfikacji: funkcja kosztu ``categorical_crossentropy``, metryka ``accuracy``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353a7936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40894ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b81dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = input_sequences[:4500]\n",
    "y_train = one_hot_labels[:4500]\n",
    "x_val = input_sequences[4500:]\n",
    "y_val = one_hot_labels[4500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e8662",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9194a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].plot(history.history['loss'], '-r', label=\"Training\")\n",
    "ax[0].plot(history.history['val_loss'], '-b', label=\"Validation\")\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], '-r', label=\"Training\")\n",
    "ax[1].plot(history.history['val_accuracy'], '-b', label=\"Validation\")\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc41c2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generowanie tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f223c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "\n",
    "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\n",
    "prediction = model.predict(token_list)\n",
    "\n",
    "predicted_token = prediction.argmax(axis=-1)\n",
    "predicted_word = tokenizer.index_word[predicted_token[0]]\n",
    "\n",
    "print('Najbardziej prawdopodobne słowo:', predicted_token, predicted_word)\n",
    "print(seed_text + ' ' + predicted_word )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af34107",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wygenerujmy dłuższą sekwencję"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "\n",
    "print(seed_text, end=\" \")\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predictions = model.predict(token_list, verbose=0)\n",
    "    predicted_token = np.argmax(predictions, axis=-1)[0]\n",
    "    output_word = tokenizer.index_word[predicted_token]\n",
    "    seed_text += \" \" + output_word\n",
    "    print(output_word, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bf617",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wprowadzanie różnowodności (losoości) do wyjścia\n",
    "\n",
    "* ten sam tekst początkowy będzie generował te same wyjścia, wybierane jest zawsze to samo najbardziej prawdopodobne następne słowo\n",
    "* uwzględnijmy pozostałe słowa, które mogą wystąpić z mniejszym prawdopodobieństwem\n",
    "* funkcja [numpy.random.choice()](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) pozwala losować elementy macierzy z zadanym rozkładem prawdopodobieństwa\n",
    "* wyjście ``softmax`` użyjemy do określenia rozkładu prawdopodobieństwa słów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ef1b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "predicted_probs = model.predict(token_list)[0]\n",
    "predicted = np.random.choice(np.arange(len(predicted_probs)), p=predicted_probs)\n",
    "\n",
    "print(predicted, tokenizer.index_word[predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efae5cfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "\n",
    "indexes = np.arange(num_words)\n",
    "print(\"im feeling chills\")\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list,verbose=0)[0]\n",
    "    predicted = np.random.choice(indexes, p=predicted_probs)\n",
    "    output_word = tokenizer.index_word[predicted]\n",
    "    seed_text += \" \" + output_word\n",
    "    print(output_word, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae545d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ćwiczenie\n",
    "\n",
    "Usprawnij działanie generatora tekstów wiosenek:\n",
    "* Wytrenuj lepszy model poprzez użycie większej architektury i/lub większej liczby tekstów (uwaga, czas treningu może znacznie się wydłużyć)\n",
    "* Zbuduj model generujący teksty piosenek z podziałem na wersy (początek i koniec linii). Wskazówka: można dodać specjalny token na końcu każdej sekwencji (np. ``[newline]``) i potraktować go jako kolejny wyraz do przewidywania. Argument ``oov_token`` konstruktora klasy ``Tokenizer()`` pozwala uwzględnić tokeny spoza słownika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b01ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487981af",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zadanie: przewidywanie ceny akcji\n",
    "\n",
    "Plik [dane/cdr_d.csv](dane/cdr_d.csv) zawiera historyczne wyceny akcji spółki giełdowej CD Projekt notowanej na GPW. Dane zawierają wartości w interwałach dziennych od momentu debiutu spółki do ostatniej sesji z dnia 9 czerwca 2023 r. \n",
    "\n",
    "Zbuduj jak najlepszy model sieci rekurencyjnej przewidujący cenę zamknięcia na podstawie historycznych notowań. \n",
    "Wykorzystaj model do wyznaczenia przewidywanej ceny akcji CDR \n",
    "* na zamkniecie sesji w następnym dniu roboczym 12 czerwca 2023 r. (+1 dzień od ostatniej wyceny) \n",
    "* oraz przewidywaną cenę zamknięcia na koniec tygodnia 23 czerwca 2023 r. (+5 dni). <br>Do wyznaczenia ceny na koniec tygodnia  wykorzystaj model autoregresji albo zbuduj model przewidujący wycenę na 5 dni do przodu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc0c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('dane/cdr_d.csv')\n",
    "df.tail()\n",
    "\n",
    "x = df['Zamkniecie'].values\n",
    "plt.plot(x);"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
