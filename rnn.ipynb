{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad41b71d",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Uczenie-sekwencji-i-sieci-RNN\" data-toc-modified-id=\"Uczenie-sekwencji-i-sieci-RNN-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Uczenie sekwencji i sieci RNN</a></span><ul class=\"toc-item\"><li><span><a href=\"#Przewidywanie-szeregów-czasowych\" data-toc-modified-id=\"Przewidywanie-szeregów-czasowych-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Przewidywanie szeregów czasowych</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sztuczen-dane\" data-toc-modified-id=\"Sztuczen-dane-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Sztuczen dane</a></span></li></ul></li><li><span><a href=\"#Okno-przesuwne\" data-toc-modified-id=\"Okno-przesuwne-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Okno przesuwne</a></span></li><li><span><a href=\"#Funkcja-timeseries_dataset_from_array()\" data-toc-modified-id=\"Funkcja-timeseries_dataset_from_array()-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Funkcja timeseries_dataset_from_array()</a></span></li><li><span><a href=\"#Podział-na-część-testową-i-treningową\" data-toc-modified-id=\"Podział-na-część-testową-i-treningową-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Podział na część testową i treningową</a></span></li><li><span><a href=\"#Model-RNN-prdykcji-szeregu-czasowego\" data-toc-modified-id=\"Model-RNN-prdykcji-szeregu-czasowego-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Model RNN prdykcji szeregu czasowego</a></span></li><li><span><a href=\"#Trening\" data-toc-modified-id=\"Trening-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Trening</a></span></li><li><span><a href=\"#Predykcja\" data-toc-modified-id=\"Predykcja-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Predykcja</a></span></li><li><span><a href=\"#Genrowanie-sekwencji-predykcji---autoregresja\" data-toc-modified-id=\"Genrowanie-sekwencji-predykcji---autoregresja-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Genrowanie sekwencji predykcji - autoregresja</a></span></li><li><span><a href=\"#Wielowarstwowe-sieci-RNN\" data-toc-modified-id=\"Wielowarstwowe-sieci-RNN-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Wielowarstwowe sieci RNN</a></span></li><li><span><a href=\"#Model-językowy---generowanie-tekstu\" data-toc-modified-id=\"Model-językowy---generowanie-tekstu-1.10\"><span class=\"toc-item-num\">1.10&nbsp;&nbsp;</span>Model językowy - generowanie tekstu</a></span></li><li><span><a href=\"#Dane:-Song-Lirycs\" data-toc-modified-id=\"Dane:-Song-Lirycs-1.11\"><span class=\"toc-item-num\">1.11&nbsp;&nbsp;</span>Dane: Song Lirycs</a></span></li><li><span><a href=\"#Przykładowa-piosenka\" data-toc-modified-id=\"Przykładowa-piosenka-1.12\"><span class=\"toc-item-num\">1.12&nbsp;&nbsp;</span>Przykładowa piosenka</a></span></li><li><span><a href=\"#Przygotowanie-korpusu\" data-toc-modified-id=\"Przygotowanie-korpusu-1.13\"><span class=\"toc-item-num\">1.13&nbsp;&nbsp;</span>Przygotowanie korpusu</a></span></li><li><span><a href=\"#Zamiana-wyrazów-na-tokeny\" data-toc-modified-id=\"Zamiana-wyrazów-na-tokeny-1.14\"><span class=\"toc-item-num\">1.14&nbsp;&nbsp;</span>Zamiana wyrazów na tokeny</a></span></li><li><span><a href=\"#Zamiana-tekstu-na-sekwencje-tokenów\" data-toc-modified-id=\"Zamiana-tekstu-na-sekwencje-tokenów-1.15\"><span class=\"toc-item-num\">1.15&nbsp;&nbsp;</span>Zamiana tekstu na sekwencje tokenów</a></span></li><li><span><a href=\"#Sekwencje-wejściowe-i-etykiety\" data-toc-modified-id=\"Sekwencje-wejściowe-i-etykiety-1.16\"><span class=\"toc-item-num\">1.16&nbsp;&nbsp;</span>Sekwencje wejściowe i etykiety</a></span></li><li><span><a href=\"#Sekwencje-o-stałej-szerokości\" data-toc-modified-id=\"Sekwencje-o-stałej-szerokości-1.17\"><span class=\"toc-item-num\">1.17&nbsp;&nbsp;</span>Sekwencje o stałej szerokości</a></span></li><li><span><a href=\"#Przygotowanie-etykiet\" data-toc-modified-id=\"Przygotowanie-etykiet-1.18\"><span class=\"toc-item-num\">1.18&nbsp;&nbsp;</span>Przygotowanie etykiet</a></span></li><li><span><a href=\"#Osadzanie-słów:-warstwa-Embedding\" data-toc-modified-id=\"Osadzanie-słów:-warstwa-Embedding-1.19\"><span class=\"toc-item-num\">1.19&nbsp;&nbsp;</span>Osadzanie słów: warstwa Embedding</a></span></li><li><span><a href=\"#Osadzanie-słów\" data-toc-modified-id=\"Osadzanie-słów-1.20\"><span class=\"toc-item-num\">1.20&nbsp;&nbsp;</span>Osadzanie słów</a></span></li><li><span><a href=\"#Model-generujący-teksty-piosenek\" data-toc-modified-id=\"Model-generujący-teksty-piosenek-1.21\"><span class=\"toc-item-num\">1.21&nbsp;&nbsp;</span>Model generujący teksty piosenek</a></span></li><li><span><a href=\"#Trening\" data-toc-modified-id=\"Trening-1.22\"><span class=\"toc-item-num\">1.22&nbsp;&nbsp;</span>Trening</a></span></li><li><span><a href=\"#Generowanie-tekstu\" data-toc-modified-id=\"Generowanie-tekstu-1.23\"><span class=\"toc-item-num\">1.23&nbsp;&nbsp;</span>Generowanie tekstu</a></span></li><li><span><a href=\"#Wprowadzanie-różnowodności-(losoości)-do-wyjścia\" data-toc-modified-id=\"Wprowadzanie-różnowodności-(losoości)-do-wyjścia-1.24\"><span class=\"toc-item-num\">1.24&nbsp;&nbsp;</span>Wprowadzanie różnowodności (losoości) do wyjścia</a></span></li><li><span><a href=\"#Zadanie:-przewidywanie-ceny-akcji\" data-toc-modified-id=\"Zadanie:-przewidywanie-ceny-akcji-1.25\"><span class=\"toc-item-num\">1.25&nbsp;&nbsp;</span>Zadanie: przewidywanie ceny akcji</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c23ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Uczenie sekwencji i sieci RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2ba458-02d1-4e53-ab02-4d02499e41be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2003d4c2-6eab-42d4-a7e8-9d34dcf9fbd5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przewidywanie szeregów czasowych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b010a-5d09-4989-a519-59d9677d9ba7",
   "metadata": {},
   "source": [
    "### Sztuczen dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ef79a-1baf-4f37-bf48-c0183f6e09b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "\n",
    "time = np.arange(N)\n",
    "signal = 0.8*np.sin(time/700) + 0.15*np.sin(time/40)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(signal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f44b88",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Okno przesuwne\n",
    "\n",
    "* szerokość okna ``window=50`` punktów czasowych\n",
    "* celem przewidyzenie kolejnej watrości w sekwencji "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f22bf-1d71-4138-a92f-de051182c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 50\n",
    "\n",
    "X = np.array(\n",
    "    [signal[t: t+window] for t in time[:-window]] \n",
    ")\n",
    "\n",
    "t = signal[time[window:]]\n",
    "\n",
    "print('Dane treningowe X', X.shape)\n",
    "print('Target ', t.shape)\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.plot(range(window), X[50], 'o-', label='time series')\n",
    "plt.plot([window], t[50], 'or', label='target')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad41c81e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Funkcja timeseries_dataset_from_array()\n",
    "\n",
    "Funkcja [tf.keras.utils.timeseries_dataset_from_array](https://www.tensorflow.org/api_docs/python/tf/keras/utils/timeseries_dataset_from_array) pozwala tworzyc zbiór danych szeregów czasowych za pomocą przesuwanego okna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb59791-fddf-4676-9d37-df55099be6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = signal[:-window]\n",
    "targets = signal[window:]\n",
    "\n",
    "dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    input_data, \n",
    "    targets, \n",
    "    sequence_length=window,\n",
    "    sequence_stride=1,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "for inputs, targets in dataset:\n",
    "    print(inputs, targets)\n",
    "    assert np.array_equal(inputs[0], signal[:window]) \n",
    "    assert np.array_equal(targets[0], signal[window])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f267c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Podział na część testową i treningową"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6423b5b4-8ab7-4e4e-a528-d2ebea040e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = 9000\n",
    "\n",
    "X_train = X[:nb_train]\n",
    "T_train = t[:nb_train]\n",
    "X_test = X[nb_train:]\n",
    "T_test = t[nb_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d57a3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model RNN prdykcji szeregu czasowego\n",
    "\n",
    "* wejście rozmiaru ``[czas, zmienne]``\n",
    "* [warstwy rekurencyjne w Keras](https://keras.io/api/layers/recurrent_layers/)\n",
    "* warstwa rekurencyjna LSTM  [tf.keras.layers.LSTM](https://keras.io/api/layers/recurrent_layers/lstm/)\n",
    "* wyjście liniowe , funkcja kosztu MSE, metryka MAE (Mean Absolute Error)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91694f61-1989-4622-a5a6-350dff0f64fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "inputs = tf.keras.layers.Input((window, 1))\n",
    "\n",
    "x = tf.keras.layers.LSTM(20)(inputs)\n",
    "\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "model = tf.keras.models.Model(inputs, output)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd9f9f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda4c348",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 30\n",
    "history = model.fit(X_train, T_train, validation_data=(X_test, T_test), epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19cfb26-ba65-41e0-869d-427ea9eda2c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].plot(history.history['loss'], '-r', label=\"Training\")\n",
    "ax[0].plot(history.history['val_loss'], '-b', label=\"Validation\")\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(history.history['mae'], '-r', label=\"Training\")\n",
    "ax[1].plot(history.history['val_mae'], '-b', label=\"Validation\")\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Mean Absolute Error')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378a501",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, T_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c324c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predykcja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c5758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "\n",
    "pred = model.predict(X_test[i].reshape(1, window, 1))\n",
    "\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.plot(range(window), X_test[i], 'o-', label='time series')\n",
    "plt.plot([window], T_test[i], 'or', label='true target')\n",
    "plt.plot([window], pred[0][0], 'xb', label='predicted')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa3acd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Genrowanie sekwencji predykcji - autoregresja\n",
    "\n",
    "Kolejka FIFO [collections.deque](https://docs.python.org/3/library/collections.html#collections.deque)\n",
    "* ``append()`` dodaj do kolejnki\n",
    "* ``popleft()`` wyjmij z kolejki\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ff735-61fa-4f11-97c3-a2dee8001d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  collections import deque\n",
    "i = 0\n",
    "\n",
    "d = deque([1, 2, 3])\n",
    "print(d)\n",
    "\n",
    "d.popleft()\n",
    "print(d)\n",
    "\n",
    "d.append(4)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9794f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "d = deque(X_test[0, :window])\n",
    "\n",
    "for t in range(950):\n",
    "    y = model.predict(np.array(d).reshape(1, window, 1), verbose=0)[0,0]\n",
    "    predictions.append(y)\n",
    "    d.popleft()\n",
    "    d.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811189b-a71c-42db-8f17-3edf65b81278",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(T_test, '-', label=\"Ground truth\")\n",
    "plt.plot(predictions, '-', label=\"Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82791959",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wielowarstwowe sieci RNN\n",
    "\n",
    "Paramert ``return_sequences`` w warstwach rekurencyjnych\n",
    "* ``return_sequences=False`` (domyślnie) zwraca pojedyncze wyjscie podsumowujące sekwencję\n",
    "* ``return_sequences=True`` zwraca wyjście dla każdego punktu sekwencji  (ewentualne wejście dla kolejnej warstwy rekurencyjnej)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a131fb5",
   "metadata": {},
   "source": [
    "## Model językowy - generowanie tekstu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad3eb49",
   "metadata": {},
   "source": [
    "## Dane: Song Lirycs\n",
    "\n",
    "Zbiór danych piosenek [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics) \n",
    "\n",
    "* cały zbiór zawiwra 57650 piosenek\n",
    "* wybierzmy pierwsze 250 piosenek \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25b7c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "n_songs = 250\n",
    "\n",
    "dataset = pd.read_csv('dane/songdata.csv.gz', compression='gzip',  dtype=str)[:n_songs]\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7ab9b6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przykładowa piosenka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f4fc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Artysta:', dataset['artist'][0])\n",
    "print('Tytuł: %s\\n' % dataset['song'][0])\n",
    "print(dataset['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0843fcb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przygotowanie korpusu \n",
    "\n",
    "* każdy wers piosenki potraktujemy jako osobną sekwencję\n",
    "* usuńmy puste linie tekstu i inne artefakty (znaki interpunkcyjne, zamieniamy wielkie litery na małe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# zbiór piosenek, usuwamy znaki przestankowe\n",
    "songs = dataset['text'].str.replace('[{}]'.format(string.punctuation), '', regex=False)\n",
    "\n",
    "# Zamiana na małe litery\n",
    "songs = songs.str.lower()\n",
    "  \n",
    "# Zamiana tekstu piosenek na długi, pojedynczy napis\n",
    "lyrics = songs.str.cat()\n",
    "\n",
    "# dzielimy tekst na linie\n",
    "corpus = lyrics.split('\\n')\n",
    "  \n",
    "# Usuwamy nadmiarowe białe znaki\n",
    "for l in range(len(corpus)):\n",
    "    corpus[l] = corpus[l].rstrip()\n",
    "\n",
    "# Usuwamy puste linie\n",
    "corpus = [l for l in corpus if l != '']\n",
    "\n",
    "print(f'Ilość linii {len(corpus)}')\n",
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3b518",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zamiana wyrazów na tokeny\n",
    "\n",
    "Klasa [tf.keras.preprocessing.text.Tokenizer()](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer)\n",
    "* tworzy słownik wyrazów, każdemu wyrazowi przypisywana jest unikatowa liczba całkwita dodatnia\n",
    "* ``num_words`` ogranicza wielkość zlownika do najczęściej występujących słów\n",
    "* ``oov_token`` (out of vocabulary) lista wyrazów, z poza słownika, które otrzymają token w słowniku (np. do obsługi szczególnych elementów, np. poczatek lub koniec sekwencji)\n",
    "* metoda ``fit_on_text()`` buduje indeks słów w oparciu o liste tekstów\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75de0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "\n",
    "num_words=2000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328c0e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "total_words = tokenizer.num_words\n",
    "\n",
    "print('Ilość słów:', total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f390f3",
   "metadata": {},
   "source": [
    "Indeks słów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f874a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.word_index['love']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a2fa0c",
   "metadata": {},
   "source": [
    "Odwzorowanie tokenów na wyrazy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bfd1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee73b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.index_word[19]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0f9851",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zamiana tekstu na sekwencje tokenów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba05df",
   "metadata": {},
   "outputs": [],
   "source": [
    "teksts = [ 'the book of love' , 'Ala ma kota' ]\n",
    "tokenizer.texts_to_sequences( teksts )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd2560",
   "metadata": {},
   "source": [
    "## Sekwencje wejściowe i etykiety\n",
    "\n",
    "* model językowy ma przewidywac najbardziej prawdopodobne kolejne słowo\n",
    "* dokumenty dzielimy na sekwencje wyrazów  (okno przesuwne)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4d227",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_corpus = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "sequences = []\n",
    "for token_list in token_corpus:\n",
    "    for i in range(2, len(token_list)+1):\n",
    "        sequences.append(token_list[:i])\n",
    "        \n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694f54cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sekwencje o stałej szerokości\n",
    "\n",
    "* tworzymy sekwencje o stałej długości (wejźmy najdłuższa linię)\n",
    "* funkcja [tf.keras.utils.pad_sequences()](https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences) uzupełnia sekwencję zerami do wymaganej długości\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import pad_sequences\n",
    "\n",
    "max_sequence_len = max([len(seq) for seq in sequences])\n",
    "\n",
    "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fac5bdc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Przygotowanie etykiet\n",
    "\n",
    "* Dzileimy sekwencję na część \"wejściową\" oraz \"wyjściową\" (przewidywane słowo).\n",
    "* Etykiety kodowane za pomoca *one hot encoding* (klasyfikacja wieloklasowa)\n",
    "* Ilośc klas to rozmiar słownika ``total_worlds``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9c718",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
    "\n",
    "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n",
    "\n",
    "print('Sekwencje wejściowe: ', input_sequences.shape)\n",
    "print('Etykiety ', one_hot_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a16801",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Osadzanie słów: warstwa Embedding\n",
    "\n",
    "W naiwnym podejściu sygnał wejściowy składałby się z ``total_worlds`` zmiennych, wejście RNN rozmiaru ``[time, total_worlds]``, to powdowałoby bardzo dużą liczbe parametrów w pierwszej warstwie\n",
    "\n",
    "![](https://www.tensorflow.org/text/guide/images/one-hot.png)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13b474",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Osadzanie słów\n",
    "\n",
    "* warstwa [Embedding(input_dim, output_dim)](https://keras.io/api/layers/core_layers/embedding/) transfromauje sekwencję liczb całkowitych dodatnich (tokenów) na gęstą reprezentację wektorową o wybranej liczbie wymiarów\n",
    "* realizowane przez gęstą (w pełni połaczoną) wartwę, uczoną wraz z siecią lub można wykorzystać wczesniej wytrenowane macierze uzyskane na dużych korpusach\n",
    "* odległości obiektów w rzutowanej przestrzeni odzwierciedlają relacje obiektów z oryginalnych sekwencji\n",
    "\n",
    "\n",
    "![](https://www.tensorflow.org/text/guide/images/embedding2.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcdf5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=total_words, output_dim=64, input_length=max_sequence_len-1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ca401d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://i.stack.imgur.com/2PznT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d18648",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model generujący teksty piosenek\n",
    "\n",
    "* warstwa wejściowa [tf.keras.layers.Embedding()](https://keras.io/api/layers/core_layers/embedding/) \n",
    "* warstwa rekurencyjna LSTM (dwukierunkowa)\n",
    "* warstwa wyjściowa o rozmiarze równym ilości słow w słowniku, funkja aktywacji ``softmax`` \n",
    "* problem klasyfikacji: funkcja kosztu ``categorical_crossentropy``, metryka ``accuracy``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(20)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660ad31d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trening "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ceeb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = input_sequences[:4500]\n",
    "y_train = one_hot_labels[:4500]\n",
    "x_val = input_sequences[4500:]\n",
    "y_val = one_hot_labels[4500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915cc71c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffd673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "ax[0].plot(history.history['loss'], '-r', label=\"Training\")\n",
    "ax[0].plot(history.history['val_loss'], '-b', label=\"Validation\")\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend();\n",
    "\n",
    "ax[1].plot(history.history['accuracy'], '-r', label=\"Training\")\n",
    "ax[1].plot(history.history['val_accuracy'], '-b', label=\"Validation\")\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a236834",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generowanie tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac44de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "\n",
    "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "\n",
    "prediction = model.predict(token_list)\n",
    "\n",
    "predicted_token = prediction.argmax(axis=-1)\n",
    "predicted_word = tokenizer.index_word[predicted_token[0]]\n",
    "\n",
    "print('Najbardziej prawdopodobne słowo:', predicted_token, predicted_word)\n",
    "print(seed_text + ' ' + predicted_word )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a976d093",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Wygenerujmy dłuższą sekwencję"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67be7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "\n",
    "print(seed_text, end=\" \")\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predictions = model.predict(token_list, verbose=0)\n",
    "    predicted_token = np.argmax(predictions, axis=-1)[0]\n",
    "    output_word = tokenizer.index_word[predicted_token]\n",
    "    seed_text += \" \" + output_word\n",
    "    print(output_word, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f08eef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Wprowadzanie różnowodności (losoości) do wyjścia\n",
    "\n",
    "* ten sam tekst początkowy bedzie generował te same wyjścia, wybierane jest zawsze to samo najbardziej prawdopodobne następne słowo\n",
    "* uwzględnijmy pozostałe słowa, które moga wystąpić z mniejszym prawdopodobieństwem\n",
    "* funkcja [numpy.random.choice()](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) pozwala losować elementy macierzy z zadanym rozkładem prawdopodobieństwa\n",
    "* wyjście ``softmax`` uzyjemy do określenia rozkładu prawdopodobieństwa słów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bcba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "  \n",
    "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "predicted_probs = model.predict(token_list)[0]\n",
    "predicted = np.random.choice(np.arange(len(predicted_probs)), p=predicted_probs)\n",
    "\n",
    "print(predicted, tokenizer.index_word[predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87faf0a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "seed_text = \"im feeling chills\"\n",
    "next_words = 100\n",
    "\n",
    "indexes = np.arange(num_words)\n",
    "print(\"im feeling chills\")\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted_probs = model.predict(token_list,verbose=0)[0]\n",
    "    predicted = np.random.choice(indexes, p=predicted_probs)\n",
    "    output_word = tokenizer.index_word[predicted]\n",
    "    seed_text += \" \" + output_word\n",
    "    print(output_word, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54978dfc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Zadanie: przewidywanie ceny akcji\n",
    "\n",
    "Plik [dane/cdr_d.csv](dane/cdr_d.csv) zawiera historyczne notowania spólki giełdowej CD Projekt notowanej na GPW od momentu debiutu spólki do ostatniej sesji z dnia 9 czerwca 2023 r. \n",
    "\n",
    "Zbuduj model sieci rekurancyjnej przewidujący cenę zamknięcia następnego dnia. \n",
    "Wykorzystaj model do wyznaczenia przewidywanej ceny akcji CDR na zamkniecie następnej sesji w dniu 12 czerwca 2023 r. (+1 dzień) oraz przewidywaną cenę zamknięcia na koniec tygodnia 23 czerwca 2023 r. (+5 dni).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4023743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('dane/cdr_d.csv')\n",
    "df.tail()\n",
    "\n",
    "x = df['Zamkniecie'].values\n",
    "plt.plot(x);"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
